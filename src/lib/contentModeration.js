// Content Moderation using Google AI Studio API (Gemini)

const GEMINI_API_KEY = import.meta.env.VITE_GEMINI_API_KEY
const GEMINI_API_URL = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent'

// Confidence threshold - below this, content goes to pending review
const CONFIDENCE_THRESHOLD = 0.7

// Debug: Log API key status (remove in production)
console.log('Gemini API Key configured:', GEMINI_API_KEY ? 'Yes (length: ' + GEMINI_API_KEY.length + ')' : 'No')

// Flag levels
export const FLAG_LEVELS = {
  NORMAL: 0,        // No issues detected
  MILD: 1,          // Mild negative language - post allowed but flagged
  IMMEDIATE: 2,     // Suicide/self-harm/depression - needs immediate attention
  BLOCKED: 3,       // Aggressive/violent/spam - auto-blocked
  PENDING: 4        // API unavailable or low confidence - pending counselor review
}

// Moderation result types
export const MODERATION_ACTIONS = {
  ALLOW: 'allow',           // Content is fine, post normally
  FLAG_MILD: 'flag_mild',   // Post but flag for review
  REJECT: 'reject',         // Don't post, notify counselors, suggest chat
  BLOCK: 'block',           // Don't post, content is aggressive/harmful/spam
  PENDING: 'pending'        // API down or low confidence - hold for counselor review
}

const MODERATION_PROMPT = `You are a content moderation AI for a mental health support platform for Vietnamese students. Analyze the following content and categorize it.

=== CRITICAL: VIETNAMESE TEENAGER SLANG ===
Pay SPECIAL ATTENTION to Vietnamese teenager slang and profanity, including but not limited to:
- "dm", "ƒëm", "d.m", "ƒë.m", "ƒë m" = "ƒë·ªãt m·∫π" (extremely vulgar, mother insult)
- "dcm", "ƒëcm", "d.c.m" = "ƒë·ªãt con m·∫π" (extremely vulgar)
- "dkm", "ƒëkm", "d.k.m" = variant of above
- "dkmm", "ƒëkmm" = "ƒë·ªãt k·∫ª m√†y m·∫π" (extremely vulgar)
- "dcmm", "ƒëcmm" = variant of above
- "vl", "v√£i l·ªìn", "vailol", "v.l" = vulgar exclamation
- "cl", "c.l", "c√°i l·ªìn" = vulgar female anatomy
- "cc", "c.c", "c·∫∑c" = vulgar male anatomy
- "ƒë√©o", "deo", "ƒë√©o", "ƒë·∫øu" = vulgar "no"
- "vcl", "v.c.l" = "v√£i c√°i l·ªìn"
- "clm" = vulgar phrase
- "ƒëƒ©", "di", "ƒë.ƒ©" = prostitute insult
- "ngu", "ngu vl", "ngu vcl" = stupid (offensive when used aggressively)
- "√≥c ch√≥", "oc cho" = dog brain (insult)
- "th·∫±ng", "con" + insults = personal attacks
- "m√†y", "tao" in aggressive context
- Any creative spellings/spacing to bypass filters (d.m, ƒë-m, ƒë_m, etc.)

Also detect SPAM patterns:
- Repeated characters/words (aaaaaaa, hahahahaha excessively)
- Promotional/advertising content
- Links to external sites (unless clearly helpful)
- Nonsensical random text
- Copy-paste spam
- Excessive emoji spam
- All caps shouting

IMPORTANT: Respond ONLY with a valid JSON object, no other text.

Categories:
1. "safe" - Normal content, no concerns
2. "mild_negative" - Mild negative emotions, sadness, stress, frustration (but not dangerous)
3. "severe_distress" - Severe emotional distress, hopelessness, but no explicit self-harm
4. "depression" - Clear signs of depression, persistent sadness, loss of interest
5. "self_harm" - Mentions of self-harm, cutting, hurting oneself
6. "suicide" - Suicidal ideation, thoughts of ending life, wanting to die
7. "aggressive" - Violent intentions, threats, bullying, hate speech, harmful to others
8. "profanity" - Contains Vietnamese slang/profanity (dm, dcm, vl, etc.) or offensive language
9. "spam" - Spam, nonsense, advertising, repetitive content, gibberish

Response format:
{
  "category": "one of the categories above",
  "confidence": 0.0 to 1.0,
  "reasoning": "brief explanation in Vietnamese",
  "keywords_detected": ["list", "of", "concerning", "words"]
}

IMPORTANT NOTES:
- Be STRICT with Vietnamese slang - even subtle variations should be caught
- If you're not confident (< 70%), still provide your best guess but with low confidence
- Spam and profanity should be blocked
- Creative spellings of profanity (d.m, d m, ƒë-m) should still be detected

Content to analyze:
"""
{CONTENT}
"""

Remember: Only output the JSON object, nothing else.`

/**
 * Analyze content using Google AI Studio (Gemini)
 * @param {string} content - The text content to analyze
 * @returns {Promise<{action: string, flagLevel: number, category: string, reasoning: string, keywords: string[]}>}
 */
export async function analyzeContent(content) {
  // Result when API fails - content goes to pending review
  const pendingResult = {
    action: MODERATION_ACTIONS.PENDING,
    flagLevel: FLAG_LEVELS.PENDING,
    category: 'pending',
    reasoning: 'API unavailable - pending counselor review',
    keywords: [],
    confidence: 0
  }

  if (!GEMINI_API_KEY) {
    console.warn('‚ùå Gemini API key not configured!')
    console.warn('Make sure VITE_GEMINI_API_KEY is set in your .env file')
    return pendingResult
  }

  if (!content || content.trim().length === 0) {
    return {
      action: MODERATION_ACTIONS.ALLOW,
      flagLevel: FLAG_LEVELS.NORMAL,
      category: 'safe',
      reasoning: 'Empty content',
      keywords: [],
      confidence: 1
    }
  }

  // Pre-check for obvious Vietnamese slang (quick filter before API call)
  const quickSlangCheck = detectVietnameseSlang(content)
  if (quickSlangCheck.detected) {
    console.log('‚ö†Ô∏è Quick slang detection:', quickSlangCheck.keywords)
    return {
      action: MODERATION_ACTIONS.BLOCK,
      flagLevel: FLAG_LEVELS.BLOCKED,
      category: 'profanity',
      reasoning: 'Ph√°t hi·ªán ng√¥n ng·ªØ t·ª•c tƒ©u: ' + quickSlangCheck.keywords.join(', '),
      keywords: quickSlangCheck.keywords,
      confidence: 0.95
    }
  }

  // Pre-check for obvious spam patterns
  const quickSpamCheck = detectSpamPatterns(content)
  if (quickSpamCheck.detected) {
    console.log('‚ö†Ô∏è Quick spam detection:', quickSpamCheck.reason)
    return {
      action: MODERATION_ACTIONS.BLOCK,
      flagLevel: FLAG_LEVELS.BLOCKED,
      category: 'spam',
      reasoning: quickSpamCheck.reason,
      keywords: [],
      confidence: 0.9
    }
  }

  try {
    console.log('üîç Analyzing content with Gemini API...')
    const prompt = MODERATION_PROMPT.replace('{CONTENT}', content)

    const response = await fetch(`${GEMINI_API_URL}?key=${GEMINI_API_KEY}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        contents: [{
          parts: [{ text: prompt }]
        }],
        generationConfig: {
          temperature: 0.1,
          maxOutputTokens: 500
        }
      })
    })

    console.log('üì° API Response status:', response.status)

    if (!response.ok) {
      const errorText = await response.text()
      console.error('‚ùå Gemini API error:', response.status, errorText)
      return pendingResult
    }

    const data = await response.json()
    console.log('‚úÖ API Response received:', data)
    
    // Extract the text response
    const textResponse = data.candidates?.[0]?.content?.parts?.[0]?.text
    
    if (!textResponse) {
      console.error('‚ùå No text in API response')
      return pendingResult
    }

    // Parse JSON from response
    const jsonMatch = textResponse.match(/\{[\s\S]*\}/)
    if (!jsonMatch) {
      console.error('‚ùå Could not parse JSON from response:', textResponse)
      return pendingResult
    }

    const analysis = JSON.parse(jsonMatch[0])
    console.log('‚úÖ Content analysis result:', analysis)
    
    // Check confidence - if too low, send to pending review
    if (analysis.confidence < CONFIDENCE_THRESHOLD && analysis.category !== 'safe') {
      console.log(`‚ö†Ô∏è Low confidence (${analysis.confidence}) - sending to pending review`)
      return {
        action: MODERATION_ACTIONS.PENDING,
        flagLevel: FLAG_LEVELS.PENDING,
        category: analysis.category,
        reasoning: `ƒê·ªô tin c·∫≠y th·∫•p (${Math.round(analysis.confidence * 100)}%) - c·∫ßn t∆∞ v·∫•n vi√™n xem x√©t. AI ph√¢n t√≠ch: ${analysis.reasoning}`,
        keywords: analysis.keywords_detected || [],
        confidence: analysis.confidence
      }
    }
    
    // Map category to action and flag level
    return mapCategoryToAction(analysis)

  } catch (error) {
    console.error('‚ùå Content moderation error:', error)
    return pendingResult
  }
}

/**
 * Quick detection of Vietnamese slang/profanity (before API call)
 */
function detectVietnameseSlang(content) {
  const normalized = content.toLowerCase()
    .normalize('NFD')
    .replace(/[\u0300-\u036f]/g, '') // Remove diacritics for matching
    .replace(/ƒë/g, 'd')
    .replace(/[._\-\s]+/g, '') // Remove separators used to bypass filters
  
  const originalLower = content.toLowerCase()
  
  // Patterns to detect (both with and without diacritics)
  const slangPatterns = [
    // Core profanity
    { pattern: /d[i·ªã]t\s*m[e·∫π]/gi, word: 'ƒë·ªãt m·∫π' },
    { pattern: /\bdm\b/gi, word: 'dm' },
    { pattern: /\bd\.m\b/gi, word: 'd.m' },
    { pattern: /\bd\sm\b/gi, word: 'd m' },
    { pattern: /\bƒëm\b/gi, word: 'ƒëm' },
    { pattern: /\bƒë\.m\b/gi, word: 'ƒë.m' },
    { pattern: /\bdcm\b/gi, word: 'dcm' },
    { pattern: /\bƒëcm\b/gi, word: 'ƒëcm' },
    { pattern: /\bd\.c\.m\b/gi, word: 'd.c.m' },
    { pattern: /\bdkm\b/gi, word: 'dkm' },
    { pattern: /\bƒëkm\b/gi, word: 'ƒëkm' },
    { pattern: /\bdkmm\b/gi, word: 'dkmm' },
    { pattern: /\bƒëkmm\b/gi, word: 'ƒëkmm' },
    { pattern: /\bdcmm\b/gi, word: 'dcmm' },
    { pattern: /\bƒëcmm\b/gi, word: 'ƒëcmm' },
    
    // Other vulgar terms
    { pattern: /\bvl\b/gi, word: 'vl' },
    { pattern: /\bv\.l\b/gi, word: 'v.l' },
    { pattern: /v[a√£]i\s*l[o·ªì][nln]/gi, word: 'v√£i l·ªìn' },
    { pattern: /\bvcl\b/gi, word: 'vcl' },
    { pattern: /\bv\.c\.l\b/gi, word: 'v.c.l' },
    { pattern: /\bcl\b/gi, word: 'cl' },
    { pattern: /\bc\.l\b/gi, word: 'c.l' },
    { pattern: /c[a√°]i\s*l[o·ªì][nln]/gi, word: 'c√°i l·ªìn' },
    { pattern: /\bcc\b/gi, word: 'cc' },
    { pattern: /\bc\.c\b/gi, word: 'c.c' },
    { pattern: /\bc[a·∫∑][ck]\b/gi, word: 'c·∫∑c' },
    { pattern: /\bclm\b/gi, word: 'clm' },
    
    // Insults
    { pattern: /\bƒë[iƒ©]\b/gi, word: 'ƒëƒ©' },
    { pattern: /con\s*ƒë[iƒ©]/gi, word: 'con ƒëƒ©' },
    { pattern: /[o√≥]c\s*ch[o√≥]/gi, word: '√≥c ch√≥' },
    
    // "ƒë√©o" variants
    { pattern: /\bƒë[e√©]o\b/gi, word: 'ƒë√©o' },
    { pattern: /\bdeo\b/gi, word: 'ƒë√©o' },
    { pattern: /\bƒë[e·∫ø]u\b/gi, word: 'ƒë·∫øu' },
  ]
  
  const detectedKeywords = []
  
  for (const { pattern, word } of slangPatterns) {
    if (pattern.test(originalLower) || pattern.test(normalized)) {
      if (!detectedKeywords.includes(word)) {
        detectedKeywords.push(word)
      }
    }
  }
  
  // Additional check on normalized text for creative spellings
  const normalizedPatterns = [
    'ditme', 'dcm', 'dkm', 'dkmm', 'dcmm',
    'vailon', 'vcl', 'cailon', 'cac', 'lon'
  ]
  
  for (const p of normalizedPatterns) {
    if (normalized.includes(p) && !detectedKeywords.some(k => k.includes(p.substring(0, 2)))) {
      detectedKeywords.push(p)
    }
  }
  
  return {
    detected: detectedKeywords.length > 0,
    keywords: detectedKeywords
  }
}

/**
 * Quick detection of spam patterns
 */
function detectSpamPatterns(content) {
  // Check for excessive character repetition (aaaaaaa, hahahahaha)
  const repetitionMatch = content.match(/(.)\1{6,}/g)
  if (repetitionMatch) {
    return {
      detected: true,
      reason: 'Ph√°t hi·ªán spam: k√Ω t·ª± l·∫∑p l·∫°i qu√° nhi·ªÅu'
    }
  }
  
  // Check for word repetition
  const words = content.toLowerCase().split(/\s+/)
  if (words.length >= 5) {
    const wordCount = {}
    for (const word of words) {
      if (word.length > 2) {
        wordCount[word] = (wordCount[word] || 0) + 1
      }
    }
    const maxRepeat = Math.max(...Object.values(wordCount))
    if (maxRepeat >= 5 && maxRepeat / words.length > 0.5) {
      return {
        detected: true,
        reason: 'Ph√°t hi·ªán spam: t·ª´ l·∫∑p l·∫°i qu√° nhi·ªÅu'
      }
    }
  }
  
  // Check for excessive caps (shouting)
  const capsRatio = (content.match(/[A-Z]/g) || []).length / content.length
  if (content.length > 20 && capsRatio > 0.7) {
    return {
      detected: true,
      reason: 'Ph√°t hi·ªán spam: vi·∫øt hoa qu√° nhi·ªÅu'
    }
  }
  
  // Check for excessive emoji
  const emojiMatch = content.match(/[\u{1F600}-\u{1F64F}\u{1F300}-\u{1F5FF}\u{1F680}-\u{1F6FF}\u{1F1E0}-\u{1F1FF}\u{2600}-\u{26FF}\u{2700}-\u{27BF}]/gu)
  if (emojiMatch && emojiMatch.length > 10) {
    return {
      detected: true,
      reason: 'Ph√°t hi·ªán spam: emoji qu√° nhi·ªÅu'
    }
  }
  
  // Check for suspicious URLs
  const urlPattern = /(https?:\/\/[^\s]+)/gi
  const urls = content.match(urlPattern)
  if (urls && urls.length > 2) {
    return {
      detected: true,
      reason: 'Ph√°t hi·ªán spam: qu√° nhi·ªÅu li√™n k·∫øt'
    }
  }
  
  // Check for gibberish/random characters
  const gibberishPattern = /[bcdfghjklmnpqrstvwxz]{5,}/gi
  if (gibberishPattern.test(content)) {
    return {
      detected: true,
      reason: 'Ph√°t hi·ªán spam: n·ªôi dung v√¥ nghƒ©a'
    }
  }
  
  return { detected: false, reason: '' }
}

/**
 * Map the AI analysis category to moderation action and flag level
 */
function mapCategoryToAction(analysis) {
  const { category, confidence, reasoning, keywords_detected } = analysis
  
  const result = {
    category,
    reasoning: reasoning || '',
    keywords: keywords_detected || [],
    confidence: confidence || 0
  }

  switch (category) {
    case 'safe':
      return {
        ...result,
        action: MODERATION_ACTIONS.ALLOW,
        flagLevel: FLAG_LEVELS.NORMAL
      }

    case 'mild_negative':
    case 'severe_distress':
      // Mild concerns - post but flag for counselor review
      return {
        ...result,
        action: MODERATION_ACTIONS.FLAG_MILD,
        flagLevel: FLAG_LEVELS.MILD
      }

    case 'depression':
    case 'self_harm':
    case 'suicide':
      // Immediate attention needed - reject post, notify counselors
      return {
        ...result,
        action: MODERATION_ACTIONS.REJECT,
        flagLevel: FLAG_LEVELS.IMMEDIATE
      }

    case 'aggressive':
    case 'profanity':
    case 'spam':
      // Block aggressive, profane, or spam content
      return {
        ...result,
        action: MODERATION_ACTIONS.BLOCK,
        flagLevel: FLAG_LEVELS.BLOCKED
      }

    default:
      // Unknown category, default to allow
      return {
        ...result,
        action: MODERATION_ACTIONS.PENDING,
        flagLevel: FLAG_LEVELS.NORMAL
      }
  }
}

/**
 * Get Vietnamese message for moderation result
 */
export function getModerationMessage(action, category) {
  switch (action) {
    case MODERATION_ACTIONS.BLOCK:
      if (category === 'spam') {
        return {
          title: 'N·ªôi dung b·ªã t·ª´ ch·ªëi',
          message: 'B√†i vi·∫øt c·ªßa b·∫°n b·ªã ph√°t hi·ªán l√† spam v√† kh√¥ng th·ªÉ ƒë∆∞·ª£c ƒëƒÉng. Vui l√≤ng vi·∫øt n·ªôi dung c√≥ √Ω nghƒ©a.',
          showChatSuggestion: false
        }
      }
      if (category === 'profanity') {
        return {
          title: 'Ng√¥n ng·ªØ kh√¥ng ph√π h·ª£p',
          message: 'B√†i vi·∫øt c·ªßa b·∫°n ch·ª©a ng√¥n ng·ªØ t·ª•c tƒ©u v√† kh√¥ng th·ªÉ ƒë∆∞·ª£c ƒëƒÉng. Vui l√≤ng s·ª≠ d·ª•ng ng√¥n ng·ªØ vƒÉn minh.',
          showChatSuggestion: false
        }
      }
      return {
        title: 'N·ªôi dung kh√¥ng ƒë∆∞·ª£c ph√©p',
        message: 'B√†i vi·∫øt c·ªßa b·∫°n ch·ª©a n·ªôi dung kh√¥ng ph√π h·ª£p v√† kh√¥ng th·ªÉ ƒë∆∞·ª£c ƒëƒÉng.',
        showChatSuggestion: false
      }

    case MODERATION_ACTIONS.REJECT:
      return {
        title: 'Ch√∫ng t√¥i quan t√¢m ƒë·∫øn b·∫°n',
        message: 'Ch√∫ng t√¥i nh·∫≠n th·∫•y b·∫°n c√≥ th·ªÉ ƒëang tr·∫£i qua giai ƒëo·∫°n kh√≥ khƒÉn. B√†i vi·∫øt n√†y kh√¥ng th·ªÉ ƒë∆∞·ª£c ƒëƒÉng c√¥ng khai, nh∆∞ng ch√∫ng t√¥i khuy·∫øn kh√≠ch b·∫°n tr√≤ chuy·ªán tr·ª±c ti·∫øp v·ªõi t∆∞ v·∫•n vi√™n ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ t·ªët h∆°n.',
        showChatSuggestion: true
      }

    case MODERATION_ACTIONS.PENDING:
      return {
        title: 'ƒêang ch·ªù duy·ªát',
        message: 'B√†i vi·∫øt c·ªßa b·∫°n ƒë√£ ƒë∆∞·ª£c g·ª≠i v√† ƒëang ch·ªù t∆∞ v·∫•n vi√™n xem x√©t. B·∫°n s·∫Ω ƒë∆∞·ª£c th√¥ng b√°o khi b√†i vi·∫øt ƒë∆∞·ª£c duy·ªát.',
        showChatSuggestion: false
      }

    case MODERATION_ACTIONS.FLAG_MILD:
      return {
        title: 'ƒê√£ ƒëƒÉng b√†i',
        message: 'B√†i vi·∫øt c·ªßa b·∫°n ƒë√£ ƒë∆∞·ª£c ƒëƒÉng. N·∫øu b·∫°n c·∫ßn h·ªó tr·ª£, ƒë·ª´ng ng·∫ßn ng·∫°i li√™n h·ªá v·ªõi t∆∞ v·∫•n vi√™n.',
        showChatSuggestion: false
      }

    default:
      return {
        title: 'ƒê√£ ƒëƒÉng b√†i',
        message: 'B√†i vi·∫øt c·ªßa b·∫°n ƒë√£ ƒë∆∞·ª£c ƒëƒÉng th√†nh c√¥ng.',
        showChatSuggestion: false
      }
  }
}

/**
 * Get flag level label in Vietnamese
 */
export function getFlagLevelLabel(level) {
  switch (level) {
    case FLAG_LEVELS.IMMEDIATE:
      return 'C·∫ßn ch√∫ √Ω ngay'
    case FLAG_LEVELS.MILD:
      return 'Theo d√µi'
    case FLAG_LEVELS.BLOCKED:
      return 'ƒê√£ ch·∫∑n'
    case FLAG_LEVELS.PENDING:
      return 'Ch·ªù duy·ªát'
    default:
      return 'B√¨nh th∆∞·ªùng'
  }
}

/**
 * Get category label in Vietnamese
 */
export function getCategoryLabel(category) {
  const labels = {
    'safe': 'An to√†n',
    'mild_negative': 'Ti√™u c·ª±c nh·∫π',
    'severe_distress': 'CƒÉng th·∫≥ng nghi√™m tr·ªçng',
    'depression': 'Tr·∫ßm c·∫£m',
    'self_harm': 'T·ª± g√¢y th∆∞∆°ng t√≠ch',
    'suicide': '√ù ƒë·ªãnh t·ª± t·ª≠',
    'aggressive': 'Hung hƒÉng/B·∫°o l·ª±c',
    'profanity': 'Ng√¥n ng·ªØ t·ª•c tƒ©u',
    'spam': 'Spam'
  }
  return labels[category] || category
}
